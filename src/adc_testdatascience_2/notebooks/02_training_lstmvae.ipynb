{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c99db648",
   "metadata": {},
   "source": [
    "# ðŸ“˜ LSTM-VAE Training Notebook\n",
    "\n",
    "In this notebook, we train an **LSTM-based encoder-decoder** architecture to perform **probabilistic one-step-ahead forecasting** of energy consumption from the `energydata_complete.csv` dataset.\n",
    "\n",
    "#### ðŸ§  How the Data is Prepared\n",
    "\n",
    "Each training sample consists of:\n",
    "\n",
    "- **Input (`X`)**: A sequence of historical multivariate sensor readings of length `input_window` (e.g., 100), **taken from the past**. To avoid data leakage, we introduce a **forecast horizon** â€” a gap between the end of the input and the prediction target. For instance, to predict `y_{t+1}`, the model receives input from `[t - 199, ..., t - 100]` â€” that is, the model learns to forecast values 100 steps ahead using earlier data.\n",
    "- **Target (`y`)**: The `\"Appliances\"` value at time step `t + 1`.\n",
    "\n",
    "This results in a forecasting task with a fixed **lead time of 100 steps**, mimicking real-world scenarios where decisions must be made in advance without access to future measurements.\n",
    "\n",
    "The model learns by minimizing a **VAE loss**, which combines:\n",
    "- Reconstruction loss (how well the predicted output matches the target),\n",
    "- KL divergence (which encourages a structured and continuous latent space for probabilistic generation).\n",
    "\n",
    "This approach not only forecasts future values but also captures the uncertainty of those forecasts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d842cd0",
   "metadata": {},
   "source": [
    "## Load libraries and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c14dbc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67a6f7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMVAE(nn.Module):\n",
    "    def __init__(self, num_input, num_hidden, num_layers, dropout, output_window, output_dim):\n",
    "        super(LSTMVAE, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = num_hidden\n",
    "        self.output_window = output_window\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.LSTM(num_input, num_hidden, num_layers, batch_first=True, dropout=dropout)\n",
    "\n",
    "        # Latent space\n",
    "        self.scale = nn.Sequential(nn.Linear(num_hidden, num_hidden), nn.Tanh())\n",
    "        self.mu = nn.Linear(num_hidden, num_hidden)\n",
    "        self.log_var = nn.Linear(num_hidden, num_hidden)\n",
    "\n",
    "        # Decoder: Linear layer maps from latent to full output window of target variable\n",
    "        self.decoder = nn.Linear(num_hidden, output_window)\n",
    "\n",
    "    def reparametrize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def encode(self, x):\n",
    "        _, (h_n, _) = self.encoder(x)  # shape: (num_layers, batch, hidden_size)\n",
    "        return self.scale(h_n[-1])     # shape: (batch, hidden_size)\n",
    "\n",
    "    def decode(self, encoded, z):\n",
    "        out = encoded * (1 + z)  # shape: (batch, hidden_size)\n",
    "        # out = encoded #* (1 + z)  # shape: (batch, hidden_size)\n",
    "        decoded = self.decoder(out)  # shape: (batch, output_window * output_dim)\n",
    "        return decoded.view(-1, self.output_window)#, self.output_dim)  # reshape to (batch, 100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encode(x)\n",
    "        mu = self.mu(encoded)\n",
    "        log_var = self.log_var(encoded)\n",
    "        z = self.reparametrize(mu, log_var)\n",
    "        decoded = self.decode(encoded, z)\n",
    "        return decoded, mu, log_var\n",
    "\n",
    "    def sample(self, x, num_samples):\n",
    "        encoded = self.encode(x).unsqueeze(1).repeat(1, num_samples, 1)\n",
    "        z = torch.randn((x.size(0), num_samples, self.hidden_size)).to(x.device)\n",
    "        decoded = self.decoder(encoded * (1 + z))\n",
    "        return decoded.view(x.size(0), num_samples, self.output_window, self.output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e33ac70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(x_hat, x_target, mu, log_var):\n",
    "    recon_loss = nn.functional.mse_loss(x_hat.squeeze(-1), x_target.squeeze(-1), reduction='mean')\n",
    "    weight = (x_target.squeeze(-1) != 0).float() + 1\n",
    "    weighted_recon_loss = torch.mean(weight * recon_loss)\n",
    "    kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp()) / x_hat.size(0)\n",
    "    return weighted_recon_loss, kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af345f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(dataframe, input_window=500, output_window=1, step=24, offset=100):\n",
    "    appliances_idx = dataframe.columns.get_loc(\"Appliances\")\n",
    "\n",
    "    X_data = dataframe.values  # full multivariate data\n",
    "    y_data = dataframe[\"Appliances\"].values  # target column\n",
    "\n",
    "    X, y = [], []\n",
    "    for i in range(0, len(dataframe) - input_window - offset - output_window + 1, step):\n",
    "        X.append(X_data[i : i + input_window])\n",
    "        y.append(y_data[i + input_window + offset : i + input_window + offset + output_window])\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    print(f\"âœ… X shape: {X.shape} (samples, input_window, input_features)\")\n",
    "    print(f\"âœ… y shape: {y.shape} (samples, output_window)\")\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def safe_rolling_sum(df, column=\"Appliances\", window=7*24*6):  # 1008\n",
    "    values = df[column].values.astype(np.float64)\n",
    "    cum = np.cumsum(np.insert(values, 0, 0))  # Pad with zero for correct diff\n",
    "    result = cum[window:] - cum[:-window]\n",
    "    padded_result = np.concatenate([np.full(window-1, result[0]), result])\n",
    "    df['Appliances_cumulative'] = padded_result\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_dataloaders(csv_path, input_window=500, output_window=100, offset=100):\n",
    "    df = pd.read_csv(csv_path, index_col=0, parse_dates=True)\n",
    "\n",
    "    # OPTIONAL: You can print this to confirm column names\n",
    "    # print(df.columns)\n",
    "    batch_size = 32\n",
    "    # Ensure all values are float32 except the index\n",
    "    df = df.astype(np.float32)\n",
    "\n",
    "    df['Appliances'] = df['Appliances'].rolling(6*6, min_periods=1).mean()\n",
    "    # df['Appliances'] = np.log1p(df['Appliances'])\n",
    "\n",
    "    # Create sequences using the DataFrame (so we can access column names)\n",
    "    X, y = create_sequences(df, input_window=input_window, output_window=output_window, offset=offset)\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X = torch.tensor(X, dtype=torch.float32)\n",
    "    y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    # Split (e.g., 70% train, 15% val, 15% test)\n",
    "    total_samples = len(X)\n",
    "    train_end = int(0.7 * total_samples)\n",
    "    val_end = int(0.85 * total_samples)\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(X[:train_end], y[:train_end])\n",
    "    val_dataset = torch.utils.data.TensorDataset(X[train_end:val_end], y[train_end:val_end])\n",
    "    test_dataset = torch.utils.data.TensorDataset(X[val_end:], y[val_end:])\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a053eb",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f68f741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… X shape: (814, 100, 26) (samples, input_window, input_features)\n",
      "âœ… y shape: (814, 1) (samples, output_window)\n"
     ]
    }
   ],
   "source": [
    "# Ensure the path is absolute and points to the same directory as this notebook\n",
    "data_path = os.path.join(os.getcwd(), \"processed_energy.csv\")\n",
    "\n",
    "# Now load\n",
    "train_loader, val_loader, _ = get_dataloaders(csv_path=data_path, input_window=100, output_window=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d27d8f1",
   "metadata": {},
   "source": [
    "## Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eec3d422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMVAE(\n",
       "  (encoder): LSTM(26, 128, num_layers=2, batch_first=True, dropout=0.3)\n",
       "  (scale): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (mu): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (log_var): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (decoder): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LSTMVAE(num_input=26, num_hidden=128, num_layers=2, dropout=0.3, output_window=1, output_dim=1)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9a91a0",
   "metadata": {},
   "source": [
    "## Define loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79e58184",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "reconstruction_loss_fn = torch.nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a093147a",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54cb870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    recon_total, kl_total = 0.0, 0.0\n",
    "    preds, targets = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            x_hat, mu, log_var = model(x_batch)\n",
    "            recon_loss, kl_loss = loss(x_hat, y_batch, mu, log_var)\n",
    "\n",
    "            recon_total += recon_loss.item() * x_batch.size(0)\n",
    "            kl_total += kl_loss.item() * x_batch.size(0)\n",
    "\n",
    "            preds.append(x_hat.cpu())\n",
    "            targets.append(y_batch.cpu())\n",
    "\n",
    "    preds = torch.cat(preds, dim=0).squeeze(-1).numpy()\n",
    "    targets = torch.cat(targets, dim=0).squeeze(-1).numpy()\n",
    "\n",
    "    mae = mean_absolute_error(targets, preds)\n",
    "    rmse = mean_squared_error(targets, preds, squared=False)\n",
    "\n",
    "    return recon_total / len(loader.dataset), kl_total / len(loader.dataset), mae, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3210ac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstmvae(model, train_loader, val_loader, device, epochs=10, save_path=None):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        recon_total, kl_total = 0.0, 0.0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            x_hat, mu, log_var = model(x)\n",
    "            recon, kl = loss(x_hat, y, mu, log_var)\n",
    "            (recon + 1e-2 * kl).backward()\n",
    "            optimizer.step()\n",
    "            recon_total += recon.item() * x.size(0)\n",
    "            kl_total += kl.item() * x.size(0)\n",
    "        \n",
    "        val_recon, val_kl, val_mae, val_rmse = evaluate(model, val_loader, device)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | TrainRecon: {recon_total/len(train_loader.dataset):.4f} \"\n",
    "              f\"| KL: {kl_total/len(train_loader.dataset):.4f} | ValRecon: {val_recon:.4f} \"\n",
    "              f\"| KL: {val_kl:.4f} | MAE: {val_mae:.4f} | RMSE: {val_rmse:.4f}\")\n",
    "    \n",
    "    if save_path:\n",
    "        torch.save(model.state_dict(), \"lstmvae_1step.pth\")\n",
    "        print(f\"âœ… Model saved to {save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2549a535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… X shape: (814, 100, 26) (samples, input_window, input_features)\n",
      "âœ… y shape: (814, 1) (samples, output_window)\n",
      "Epoch 1/10 | TrainRecon: 0.0092 | KL: 0.1304 | ValRecon: 0.0048 | KL: 0.0117 | MAE: 0.0384 | RMSE: 0.0492\n",
      "Epoch 2/10 | TrainRecon: 0.0074 | KL: 0.0068 | ValRecon: 0.0048 | KL: 0.0043 | MAE: 0.0377 | RMSE: 0.0492\n",
      "Epoch 3/10 | TrainRecon: 0.0073 | KL: 0.0044 | ValRecon: 0.0048 | KL: 0.0024 | MAE: 0.0334 | RMSE: 0.0488\n",
      "Epoch 4/10 | TrainRecon: 0.0064 | KL: 0.0021 | ValRecon: 0.0042 | KL: 0.0017 | MAE: 0.0328 | RMSE: 0.0459\n",
      "Epoch 5/10 | TrainRecon: 0.0069 | KL: 0.0015 | ValRecon: 0.0050 | KL: 0.0012 | MAE: 0.0321 | RMSE: 0.0499\n",
      "Epoch 6/10 | TrainRecon: 0.0067 | KL: 0.0014 | ValRecon: 0.0043 | KL: 0.0013 | MAE: 0.0302 | RMSE: 0.0461\n",
      "Epoch 7/10 | TrainRecon: 0.0063 | KL: 0.0007 | ValRecon: 0.0045 | KL: 0.0006 | MAE: 0.0307 | RMSE: 0.0473\n",
      "Epoch 8/10 | TrainRecon: 0.0065 | KL: 0.0007 | ValRecon: 0.0050 | KL: 0.0006 | MAE: 0.0315 | RMSE: 0.0502\n",
      "Epoch 9/10 | TrainRecon: 0.0062 | KL: 0.0004 | ValRecon: 0.0044 | KL: 0.0003 | MAE: 0.0306 | RMSE: 0.0468\n",
      "Epoch 10/10 | TrainRecon: 0.0063 | KL: 0.0004 | ValRecon: 0.0047 | KL: 0.0004 | MAE: 0.0320 | RMSE: 0.0483\n",
      "âœ… Model saved to lstmvae_1step.pth\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "data_path = os.path.join(\"processed_energy.csv\")\n",
    "model_save_path = os.path.join(\"lstmvae_1step.pth\")  # You can still nest outputs\n",
    "\n",
    "# Initialize and train the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader, val_loader, _ = get_dataloaders(data_path, 100, 1)\n",
    "model = LSTMVAE(26, 128, 2, 0.3, 1, 1)\n",
    "train_lstmvae(model, train_loader, val_loader, device, epochs=10, save_path=model_save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001dab28",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8debb193",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
